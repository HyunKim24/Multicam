<< 프로젝트 관점은 데이터를 얻을 수 있는지가 관건 >>

1. 데이터 수집(순차적으로 적용)
> 데이터 클라우드, 관공서 등 데이터를 제공 받으면 가장 best
  통상 개인정보 등등 보안 이슈 때문에 제공을 하지 않는다.
  open data ->csv가 가장 편함

> API를 제공하면 이를 이용하여 수집

> request를 이용하여 html을 획득
  bs4를 이용하여 데이터 추출 수집
=> 로그인 할 필요 없는 사이트 
## urllib.request 웹에서 긁을때 가장 중요한 라이브러리

> selenium을 이용하여 자동화 처리 후
  데이터를 추출 수집
=> 로그인 및 인증이 필요한 사이트, 가입한 카페만 접근 가능
   파일로 존재해서 사람의 손을 타야할때

2. 데이터 전처리 (여기서는 정규화를 이용한 전처리)
> 분석전에 수행
> 텍스트 정리
> => 데이터 분석쪽(numpy, pandas...)
  수치 보정, 타입보정, 필요한 값 추출...

3. 데이터 분석
> 시각화(데이터를 이해, 분석 결과를 보여주고 등등)
> 통계적인 접근을 통해 결론을 도출

4. 예측: 머신러닝, 딥러닝등 학습을 통해
   예측을 하는 방식으로 갈 수도 있다.

5. 빅데이터 분석
> 하둡 시스템을 구축(병렬 구성)
  기가 이상 단위의 데이터를 하둡에 설정하여서
  + 머신러닝(많고), 딥러닝등등 연결하여 학습>예측
  예측의 정확도!!